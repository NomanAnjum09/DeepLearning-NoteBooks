{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c16302e8c919>:1: read_data_sets (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From /home/noman/B Drive/Codes/Practice/Python/Deep Learning/ConvNet/input_data.py:296: _maybe_download (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/noman/B Drive/Codes/Practice/Python/Deep Learning/ConvNet/input_data.py:299: _extract_images (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/noman/B Drive/Codes/Practice/Python/Deep Learning/ConvNet/input_data.py:304: _extract_labels (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/noman/B Drive/Codes/Practice/Python/Deep Learning/ConvNet/input_data.py:112: _dense_to_one_hot (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/noman/B Drive/Codes/Practice/Python/Deep Learning/ConvNet/input_data.py:328: _DataSet.__init__ (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/fashion',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set(image) shape:(55000, 784)\n",
      "Training set(label) shape:(55000, 10)\n",
      "Test set(image) shape:(10000, 784)\n",
      "Test set(label) shape:(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Training set(image) shape:{}'.format(data.train.images.shape))\n",
    "print('Training set(label) shape:{}'.format(data.train.labels.shape))\n",
    "print('Test set(image) shape:{}'.format(data.test.images.shape))\n",
    "print('Test set(label) shape:{}'.format(data.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label_dict ={\n",
    "    0:'T-shrit/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot'\n",
    "}\n",
    "\n",
    "print(data.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping Data to 28 X 28\n",
    "train_X = data.train.images.reshape(-1,28,28,1)\n",
    "test_X = data.test.images.reshape(-1,28,28,1)\n",
    "train_X.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traing_iters = 200\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "n_input = 28\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "x = tf.compat.v1.placeholder('float',[None,28,28,1])\n",
    "y= tf.compat.v1.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W,b,strides=1):\n",
    "    #conv2d wrapper with bias and relu\n",
    "    x = tf.nn.conv2d(x,W,strides=[1,strides,strides,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x,k=2):\n",
    "    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noman/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'wc1':tf.compat.v1.get_variable('W0',shape=(3,3,1,32),initializer=tf.keras.initializers.GlorotNormal()),\n",
    "    'wc2':tf.compat.v1.get_variable('W1',shape=(3,3,32,64),initializer=tf.keras.initializers.GlorotNormal()),\n",
    "    'wc3':tf.compat.v1.get_variable('W2',shape=(3,3,64,128),initializer=tf.keras.initializers.GlorotNormal()),\n",
    "    'wd1':tf.compat.v1.get_variable('W3',shape=(4*4*128,128),initializer=tf.keras.initializers.GlorotNormal()),\n",
    "    'out':tf.compat.v1.get_variable('W4',shape=(128,n_classes),initializer=tf.keras.initializers.GlorotNormal())\n",
    "\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1':tf.compat.v1.get_variable('B0',shape=(32),initializer = tf.keras.initializers.GlorotNormal()),\n",
    "    'bc2':tf.compat.v1.get_variable('B1',shape=(64),initializer = tf.keras.initializers.GlorotNormal()),\n",
    "    'bc3':tf.compat.v1.get_variable('B2',shape=(128),initializer = tf.keras.initializers.GlorotNormal()),\n",
    "    'bd1':tf.compat.v1.get_variable('B3',shape=(128),initializer= tf.keras.initializers.GlorotNormal()),\n",
    "    'out':tf.compat.v1.get_variable('B4',shape=(n_classes),initializer = tf.keras.initializers.GlorotNormal()),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x,weight,biases):\n",
    "    conv1 = conv2d(x,weight['wc1'],biases['bc1'])\n",
    "    #max pooling (downsampling) this chooses the max value from 2*2 matrix \n",
    "    #and output 14*14 matrix\n",
    "    conv1 = maxpool2d(conv1,k=2)\n",
    "    \n",
    "    conv2 = conv2d(conv1,weight['wc2'],biases['bc2'])\n",
    "    #max pooling (downsampling) this chooses the max value from 2*2 matrix \n",
    "    #and output 14*14 matrix\n",
    "    conv2 = maxpool2d(conv2,k=2)\n",
    "    \n",
    "    conv3 = conv2d(conv2,weight['wc3'],biases['bc3'])\n",
    "    #max pooling (downsampling) this chooses the max value from 2*2 matrix \n",
    "    #and output 14*14 matrix\n",
    "    conv3 = maxpool2d(conv3,k=2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    #reshape conv2d output  to fit fully conncted layer input\n",
    "    \n",
    "    fc1 = tf.reshape(conv3,[-1,weight['wd1'].get_shape().as_list()[0]])\n",
    "    fc1= tf.add(tf.matmul(fc1,weight['wd1']),biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    #output class prediction \n",
    "    #we multiply fully connectd layer with wieghts and add biases\n",
    "    \n",
    "    out = tf.add(tf.matmul(fc1,weight['out']),biases['out'])\n",
    "    \n",
    "    return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conv_net(x,weights,biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we check if index of max of predictd image is equal to actual label\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "\n",
    "#calculate accuracy across all image and avg them out\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    for i in range(traing_iters):\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = data.train.labels[batch*batch_size:min((batch+1)*batch_size,len(data.train.labels))]\n",
    "            \n",
    "            # Run optimizer op\n",
    "            # calculate batch loss and acc\n",
    "            \n",
    "            opt = sess.run(optimizer,feed_dict={x:batch_x,y:batch_y})\n",
    "            \n",
    "            loss,acc = sess.run([cost,accuracy],feed_dict={x:batch_x,y:batch_y})\n",
    "            \n",
    "            print(\"Iter\"+str(i)+\" , Loss = {} Training Accuracy {}\".format(loss,acc))\n",
    "            \n",
    "            #Calculate accuracy for all 10000 mnist test images\n",
    "            test_acc,valid_loss = sess.run([accuracy,cost],feed_dict={x:test_X,y=data.test.labels})\n",
    "            train_loss.append(loss)\n",
    "            test_loss.append(valid_loss)\n",
    "            train_accuracy.append(acc)\n",
    "            test_accuracy.append(test_acc)\n",
    "            print(\"Testing Accuracy: {}\".format(test_acc))\n",
    "        \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
